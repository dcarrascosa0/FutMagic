# EuroCupÂ Predictor âš½ï¸ğŸ“Š

**Author â€” DavidÂ CarrascosaÂ Victori**  
Fullâ€‘stack analytics platform that ingests detailed match statistics, persists them in a relational database, computes team performance aggregations, and exposes a Flask + Bootstrap UI (and JSON API) to explore data for EuroÂ 2024 predictions.

---
## â­ï¸Â Core capabilities

| | |
|---|---|
| **Data ingestion** | Import raw match Python files (`/src/main/db/data/*.py`) with `insert_matches_data.py`; new matches are skipped automatically if already present. |
| **Relational model** | Normalised schema for **Matches**, **Teams**, and 6 granular stat tables (Key, Attacking, Distribution, Defending, Goalkeeping, Disciplinary). |
| **Stat engine** | Average calculators (`compute_average_stats`) and flexible aggregators (`get_team_data.py`) for any team. |
| **RESTÂ API** | `/teams`, `/team/<id>/stats`, `/team/<id>/match/<id>/stats` return JSON for frontâ€‘end or ML consumers. |
| **Web UI** | Singleâ€‘page Bootstrap interface (accordion tabs) to drill down from overall team averages âœ individual match details. |

---
## ğŸ—‚Â Repository layout

```text
futMagic/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”‚   â”œâ”€â”€ get_team_data.py      #Â JSON summary per team
â”‚   â”‚   â”‚   â””â”€â”€ get_team_stats.py     #Â CLI summary printout
â”‚   â”‚   â””â”€â”€ db/
â”‚   â”‚       â”œâ”€â”€ data/                 #Â raw match stat files (one module per match)
â”‚   â”‚       â”œâ”€â”€ insert_matches_data.py#Â ETL loader
â”‚   â”‚       â”œâ”€â”€ migrate.py            #Â creates tables
â”‚   â”‚       â””â”€â”€ schema.py             #Â SQLAlchemy models
â”‚   â””â”€â”€ test/                         #Â pytest / notebooks
â”œâ”€â”€ static/styles.css                 #Â UI styling
â”œâ”€â”€ templates/index.html              #Â Bootstrap front end
â”œâ”€â”€ app.py                            #Â Flask server & API routes
â”œâ”€â”€ .env                              #Â DATABASE_URL=postgresql://â€¦
â””â”€â”€ requirements.txt                  #Â libs (SQLAlchemy, Flask, pythonâ€‘dotenvâ€¦)
```

---
## ğŸš€Â Quick start

### 1Â â€” setup
```bash
git clone https://github.com/yourâ€‘org/eurocupâ€‘predictor.git
cd eurocupâ€‘predictor
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

Create **.env** in project root:
```env
DATABASE_URL=postgresql://user:password@localhost:5432/eurocup
```
Create a Postgres DB called `eurocup` (or adjust the URL).

### 2Â â€” migrate & load sample data
```bash
python src/main/db/migrate.py               #Â creates tables
python src/main/db/insert_matches_data.py   #Â parses data/*.py âœ inserts stats
```

### 3Â â€” run the server
```bash
python app.py        #Â Flask dev server on http://127.0.0.1:5000
```
Open **http://127.0.0.1:5000** to interact with the UI.

---
## ğŸ”ŒÂ API reference

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/teams` | GET | List all teams (`[{team_id, team_name}]`). |
| `/team/<team_id>/stats` | GET | Average + perâ€‘match stats for the team. |
| `/team/<team_id>/match/<match_id>/stats` | GET | All stat categories for the team in one match. |

All responses are JSON; errors return `4xx` with `{"error": â€¦}`.

---
## ğŸ§®Â Stat computation flow

1. **Raw rows** queried by `team_id` (and optionally `match_id`).
2. Each SQLAlchemy model â†’ plain dict via `serialize_sqlalchemy_object`.
3. `compute_average_stats()` sums columns and divides by sample count.
4. Endpoint bundles `average_stats` and `individual_stats` into JSON.

For offline analysis, use `src/main/analysis/get_team_data.py` to obtain the same structure directly from Python.

---
## ğŸ› Â Development tips

* **Logging** â€” all API routes use Python `logging`; raise to `INFO`/`DEBUG` as needed.
* **Hot reload** â€” `FLASK_ENV=development flask run` for autoâ€‘reload.
* **Unit tests** â€” create fixtures with an inâ€‘memory SQLite URI (`sqlite:///:memory:`) to test ETL and endpoint logic without Postgres.
* **Data updates** â€” drop new `*.py` files into `src/main/db/data/` and rerun `insert_matches_data.py`; duplicates are ignored.

---
## ğŸŒÂ Roadmap ideas

- xG (expected goals) and other advanced metrics tables.
- Predictive model endpoint (`/predict`) using scikitâ€‘learn or TensorFlow.
- Caching layer (Redis) for heavy aggregate queries.
- Docker Compose with Postgres + app service.

---
## ğŸ“„Â License

MIT Â©Â 2025Â DavidÂ CarrascosaÂ Victori

